{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Asynchronous Advantage Actor-Critic (A3C)\n",
    "In this example, we use an implementation of the A3C algorithm to teach the agent how to play Doom, that classic 1993 game we played all the way through the 2000s on our calculators in math class.\n",
    "\n",
    "Requires the VizDoom package: `pip install vizdoom`\n",
    "\n",
    "While training is taking place, statistics on agent performance are available from Tensorboard. To launch it, use:\n",
    "\n",
    "`tensorboard --logdir=worker_0:'./train_0',worker_1:'./train_1',worker_2:'./train_2',worker_3:'./train_3'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python35\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\python35\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from a3c import ACNetwork, Worker\n",
    "from helper import *\n",
    "from scipy.signal import lfilter\n",
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_episode_length = 300\n",
    "gamma = 0.99\n",
    "lr = 1e-4\n",
    "img_sz = 84\n",
    "buffer_sz = 30\n",
    "s_size = 7056  # Observations are grayscale frames of 84*84*1\n",
    "a_size = 3     # Agent can move left, right, or fire\n",
    "load_model = False\n",
    "model_dir = 'model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "    \n",
    "if not os.path.exists('frames'):\n",
    "    os.makedirs('frames')\n",
    "    \n",
    "with tf.device('/cpu:0'):\n",
    "    global_episodes = tf.Variable(0, dtype = tf.int32, name = 'global_episodes', trainable = False)\n",
    "    trainer = tf.train.AdamOptimizer(learning_rate = lr)\n",
    "    master_network = ACNetwork(s_size, a_size, img_sz, 'global', None)\n",
    "    num_workers = multiprocessing.cpu_count()\n",
    "    workers = []\n",
    "    # Create the Workers\n",
    "    for i in range(num_workers):\n",
    "        workers.append(\n",
    "            Worker(\n",
    "                DoomGame(), i, s_size, a_size, buffer_sz,\n",
    "                trainer, model_dir, global_episodes\n",
    "            )\n",
    "        )\n",
    "    saver = tf.train.Saver(max_to_keep = 5)\n",
    "    \n",
    "with tf.Session() as sess:\n",
    "    coord = tf.train.Coordinator()\n",
    "    if load_model:\n",
    "        print('Loading model...')\n",
    "        ckpt = tf.train.get_checkpoint_state(model_path)\n",
    "        saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "    else:\n",
    "        sess.run(tf.global_variables_initializer)\n",
    "        \n",
    "    # This is where the asynchronous magic happens. Start the \"work\"\n",
    "    # process for each Worker in a separate thread\n",
    "    worker_threads = []\n",
    "    for worker in workers:\n",
    "        worker_work = lambda: worker.work(max_episode_length, gamma, sess, coord, saver)\n",
    "        t = threading.Thread(target = (worker_work))\n",
    "        t.start()\n",
    "        sleep(0.5)\n",
    "        worker_threads.append(t)\n",
    "    coord.join(worker_threads)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
