{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Asynchronous Advantage Actor-Critic (A3C)\n",
    "In this example, we use an implementation of the A3C algorithm to teach the agent how to play Doom, that classic 1993 game we played all the way through the 2000s on our calculators in math class.\n",
    "\n",
    "Requires the VizDoom package: `pip install vizdoom`\n",
    "\n",
    "While training is taking place, statistics on agent performance are available from Tensorboard. To launch it, use:\n",
    "\n",
    "`tensorboard --logdir=worker_0:'./train_0',worker_1:'./train_1',worker_2:'./train_2',worker_3:'./train_3'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from a3c import ACNetwork\n",
    "from helper import *\n",
    "from scipy.signal import lfilter\n",
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copies values from one set of variables to another\n",
    "# Used to set the worker networks' weights to those of the global network's\n",
    "def update_target_graph(from_scope, to_scope):\n",
    "    from_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, from_scope)\n",
    "    to_vars   = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, to_scope)\n",
    "    # We'll return the graph operations that will do the variable assignment in a list\n",
    "    op_holder = []\n",
    "    for from_var, to_var in zip(from_vars, to_vars):\n",
    "        op_holder.append(to_var.assign(from_var))\n",
    "    return op_holder\n",
    "\n",
    "# Calculates and returns discounted rewards\n",
    "def discount(x, gamma):\n",
    "    return lfilter([1], [1, -gamma], x[::,-1], axis = 0)[::-1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
